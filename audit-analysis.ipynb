{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9517c898",
   "metadata": {},
   "source": [
    "## Import and setup of custom helper functions\n",
    "\n",
    "Just a quick step to import libraries and define convenience functions that simplify data manipulation, renaming columns, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9a2af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter \n",
    "import datetime as dt\n",
    "pd.set_option('display.max_columns',50)\n",
    "pd.set_option('display.max_rows',100)\n",
    "pd.set_option('display.width', 500)\n",
    "\n",
    "\n",
    "def string_to_date(datestr, dt_format=\"%m/%y\"):\n",
    "    return dt.datetime.strptime(datestr, dt_format)\n",
    "\n",
    "def date_diff(start_date, end_date):\n",
    "    return (end_date-start_date).days\n",
    "\n",
    "def redo_colnames(colnames, level=0):\n",
    "    newnames = []\n",
    "    if isinstance(colnames, pd.MultiIndex):\n",
    "        for col in colnames:\n",
    "            newnames.append(col[level].replace('_',' ').capitalize())\n",
    "    else:\n",
    "        for col in colnames:\n",
    "            newnames.append(col.repalce('_',' ').capitalize())\n",
    "    return newnames\n",
    "\n",
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    percentile_.__name__ = 'p%s' % n\n",
    "    return percentile_\n",
    "\n",
    "def spd(sensitive_attribute, dataset, predicted_labels, majority_class, minority_class):\n",
    "    # Compute the spd value\n",
    "    \n",
    "    majority_predicted = predicted_labels[dataset[sensitive_attribute] == majority_class]\n",
    "    minority_predicted = predicted_labels[dataset[sensitive_attribute] == minority_class]\n",
    "    spd_val = minority_predicted.mean() - majority_predicted.mean()\n",
    "\n",
    "    return spd_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05084e5",
   "metadata": {},
   "source": [
    "## EDA & Data Distribution\n",
    "\n",
    "To start off, we present some basic plots and EDA that provide insights on the distribution of the features in the dataset. Along the way we also define functions that manipulate applicant information to simplify the analysis.\n",
    "\n",
    "A quick note to bear: we found it advantageous to generate identical samples multiple times to gauge the variability in the models\\' outputs. With such a strategy we repeated each sample 10 times, for a set of 4000 distinct applicants, totaling 40000 rows of data. In this synthetic dataset each feature was drawn independently from a random distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda07fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/audit-data.csv', keep_default_na=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de58482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datestr_diff(start_str, end_str):\n",
    "    if pd.isna(start_str) or start_str==\"N/A\":\n",
    "        return 0\n",
    "    else:\n",
    "        start_dt = string_to_date(start_str)\n",
    "        \n",
    "    if pd.isna(end_str) or end_str==\"N/A\":\n",
    "        end_dt = dt.datetime.today()\n",
    "    else:\n",
    "        end_dt = string_to_date(end_str)\n",
    "    \n",
    "    exp = date_diff(start_dt, end_dt)\n",
    "    return exp\n",
    "\n",
    "vec_datestr_diff = np.vectorize(datestr_diff)\n",
    "\n",
    "\n",
    "df['role1_exp'] = vec_datestr_diff(df['start1'], df['end1'])\n",
    "df['role2_exp'] = vec_datestr_diff(df['start2'], df['end2'])\n",
    "df['role3_exp'] = vec_datestr_diff(df['start3'], df['end3'])\n",
    "df['total_exp'] = (df['role1_exp']+df['role2_exp']+df['role3_exp'])//365\n",
    "\n",
    "\n",
    "df['exp_yrs'] = pd.cut(df['total_exp'], bins=[0,1,3,5,10,15,100], \n",
    "                       labels=['00-01 yr','01-03 yr','03-05 yr','05-10 yr','10-15 yr','15+ yr'],\n",
    "                       include_lowest=True, right=False)\n",
    "\n",
    "df['num_jobs'] = np.sum(df[['role1_exp','role2_exp','role3_exp']].values>0, axis=1)\n",
    "\n",
    "df['job21_gap'] = vec_datestr_diff(df['end2'], df['start1'])\n",
    "df['job32_gap'] = vec_datestr_diff(df['end3'], df['start2'])\n",
    "df['job_gap_months'] = (df['job21_gap']+df['job32_gap'])//30\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e89eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['exp_yrs','num_jobs']).agg({'applicant_id':'count'}).reset_index().\\\n",
    "rename(columns={'applicant_id':'Number of applications', 'exp_yrs':'Experience', 'num_jobs':'Number of jobs'}).\\\n",
    "pivot_table(index=['Number of jobs'], columns=['Experience'], aggfunc=sum, margins=True, margins_name='Total')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c00f2c",
   "metadata": {},
   "source": [
    "The table above shows the distribution of application profiles. 3280 applications demonstrate no job history and have less than 1 year of experience. Likewise 10,320 demonstrate some job history but less than 3 years of work experience. The purpose of setting such a distribution was to ensure that different applicant profiles are well represented in our dataset.\n",
    "\n",
    "Similarly, with sensitive features like gender and ethnicity, we have tried to achieve a rather uniform distribution. The same is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['gender','ethnicity']).agg({'applicant_id':'count'}).reset_index().\\\n",
    "rename(columns={'applicant_id':'Number of applications', 'gender':'Gender', 'ethnicity':'Ethnicity'}).\\\n",
    "pivot_table(index=['Gender'], columns=['Ethnicity'], aggfunc=sum, margins=True, margins_name='Total')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ec75e",
   "metadata": {},
   "source": [
    "Finally, we look at the distribution of degrees and GPA. It's clear from the graphs below that degrees are distributed uniformly, while GPA is built from a normal distribution, clipped at a GPA of 4.0. The details can be found in the datagenerator file that handles generation of the synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bar plot for degree in percentage\n",
    "degree = ['Bachelor\\'s', 'Master\\'s', 'PhD']\n",
    "\n",
    "temp_df_degree = df.groupby(by='degree').size()/df.groupby(by='degree').size().sum()\n",
    "temp_df_degree.plot(kind='bar')\n",
    "\n",
    "# rotate the x-axis labels\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# add title and labels\n",
    "plt.title('Distribution of Degrees')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Percentage of Samples')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1, 0))\n",
    "\n",
    "# save as png\n",
    "plt.savefig('plots/degree-dist.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a98bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distribution of GPA density in a histogram, remove grid and add n_bins\n",
    "plt.hist(df['gpa'], weights=np.ones(len(df['gpa'])) / len(df['gpa']), \n",
    "         color='tab:orange', alpha=0.65, edgecolor='tab:orange', bins=20)\n",
    "\n",
    "# add title and labels\n",
    "plt.title('Distribution of GPA')\n",
    "plt.xlabel('GPA')\n",
    "plt.ylabel('Percentage of samples')\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "# save as png\n",
    "plt.savefig('plots/gpa-dist.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036ee2c",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Now that we have completed describing different features of the synthetic dataset, and drawn some insights on the distributions, we'll move on to analyzing the resume scorer and candidate evaluator models. Bearing that each distinct sample is queried 10 times, we can find a mean score and mean selection rate for each of the 4000 distinct applicants. The dataframe `dedup_df` enables such an analysis scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_selection_rate'] = df.groupby(['group_idx'])['prediction'].transform('mean')\n",
    "df['std_selection_rate'] = df.groupby(['group_idx'])['prediction'].transform(np.std)\n",
    "df['mean_resume_score'] = df.groupby(['group_idx'])['resume_score'].transform('mean')\n",
    "df['std_resume_score'] = df.groupby(['group_idx'])['resume_score'].transform(np.std)\n",
    "\n",
    "\n",
    "dedup_df = df[['group_idx','jobref_id','school_name','gpa','degree','location','gender',\n",
    "               'veteran_status','work_auth','disability','ethnicity','exp_yrs', 'num_jobs',\n",
    "               'job_gap_months','mean_selection_rate','std_selection_rate','mean_resume_score',\n",
    "               'std_resume_score']].drop_duplicates()\n",
    "\n",
    "score_bins = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "dedup_df['mean_resume_score_bins'] = pd.cut(dedup_df['mean_resume_score'], bins=score_bins,\n",
    "                                            right=False, include_lowest=True)\n",
    "\n",
    "gpa_bins = [0,1.0,2.0,3.0,4.0001]\n",
    "dedup_df['gpa_bins'] = pd.cut(dedup_df['gpa'], bins=gpa_bins, right=False, include_lowest=True)\n",
    "dedup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a198c05",
   "metadata": {},
   "source": [
    "### Gender based discrepancies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1edff6d",
   "metadata": {},
   "source": [
    "\n",
    "For our first insight, we saw a marked bias in the selection of female candidates and individuals who refused to divulge gender information either because they're non-binary or other personal reasons. What stands out is that the resume scores are similar, but the selection rate are vastly higher for male candidates. This is also beyond any reasonable bounds such as the $\\frac{4}{5}^{\\text{th}}$ rule. \n",
    "\n",
    "The table below highlights the same and shows that controlling for a similar sample size, while the mean resume scores and their standard deviations-- and by extension the standard errors, since group size is consistent at 10-- the candidate evaluator model's selection rate is vastly different. The mean and median selection rates highlight this difference-- where individuals identifying as female have a 38% lower selection rate when compared to men. For those who deny sharing gender information or identify as non-binary the selection rate is 0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_group_df = dedup_df.groupby(['gender']).agg({'group_idx':['count'],\n",
    "                                                    'mean_resume_score':['mean'],\n",
    "                                                    'std_resume_score':['mean'],\n",
    "                                                    'mean_selection_rate':['mean',percentile(50)]})\n",
    "\n",
    "rename_map = {('group_idx', 'count'): 'Number of applicants',\n",
    "              ('mean_resume_score', 'mean'): 'Mean resume score',\n",
    "              ('std_resume_score', 'mean'): 'Std dev resume score',\n",
    "              ('mean_selection_rate', 'mean'): 'Mean selection rate',\n",
    "              ('mean_selection_rate', 'p50'): 'Median selection rate'}\n",
    "\n",
    "gender_group_df.columns = [rename_map[tuple(col)] for col in gender_group_df.columns]\n",
    "gender_group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2675f5",
   "metadata": {},
   "source": [
    "The above analysis can also be viewed through the lens of fairness metrics covered in class. \n",
    "\n",
    "Let's consider the statistical parity difference (SPD)-- defined as the difference between the proportion of positive outcomes for the majority and minority groups. Mathematically,\n",
    "\n",
    "$$\\text{SPD} = \\mathbb{P}(\\hat{Y} = 1|A = \\text{minority}) - \\mathbb{P}(\\hat{Y} = 1|A = \\text{majority})$$\n",
    "\n",
    "Setting the predicted outcome $\\left(\\hat{Y}\\right)$, in the above equation, to be output of the candidate evaluator model we can see that $\\mathbb{P}(\\hat{Y} = 1|A = \\text{minority})  = \\mathbb{E}(\\hat{Y}|A = \\text{minority})$, since our outcome is binary. Thus, substituting the mean selection rate in the above equation, we find that: \n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{SPD}_{\\text{f-m}} &= \\mathbb{E}(\\hat{Y}|\\text{gender} = \\text{female}) - \\mathbb{E}(\\hat{Y}|\\text{gender} = \\text{male}) \\\\\n",
    "&= 0.3313 - 0.5300 = -0.1987\n",
    "\\end{align*}$$\n",
    "\n",
    "Likewise, for non-binary individuals, we see:\n",
    "$$\\begin{align*}\n",
    "\\text{SPD}_{\\text{na-m}} &= \\mathbb{E}(\\hat{Y}|\\text{gender} = \\text{N/A}) - \\mathbb{E}(\\hat{Y}|\\text{gender} = \\text{male}) \\\\\n",
    "&= 0.00 - 0.53 = -0.53\n",
    "\\end{align*}$$\n",
    "\n",
    "<br><br>\n",
    "Disparate impact is very similar to SPD, except that it is a ratio of the above proportions as opposed to a difference. Mathematically, \n",
    "$$\\text{DI} = \\dfrac{\\mathbb{P}(\\hat{Y} = 1|A = \\text{minority})}{\\mathbb{P}(\\hat{Y} = 1|A = \\text{majority})}$$\n",
    "\n",
    "As before, since our model is binary $\\mathbb{P}(\\hat Y = 1 | A = a) = \\mathbb{E}(\\hat Y | A = a)$, we modify the above equation with mean selection rate arrived at above, finding:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{DI}_{\\text{f/m}} &= \\dfrac{\\mathbb{E}(\\hat{Y}|\\text{gender} = \\text{female})}{\\mathbb{E}(\\hat{Y}|\\text{gender} = \\text{male})} \\\\\n",
    "&= \\dfrac{0.3313}{0.5300} = 0.625\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Similarly, for non-binary individuals:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{DI}_{\\text{na/m}} &= \\dfrac{\\mathbb{E}(\\hat{Y}|\\text{gender} = \\text{N/A})}{\\mathbb{E}(\\hat{Y}|\\text{gender} = \\text{male})} \\\\\n",
    "&= \\dfrac{0.00}{0.5300} = 0.0\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb077b63",
   "metadata": {},
   "source": [
    "### Job gap based discrepancies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_gap_months_group_df = dedup_df.groupby(['job_gap_months']).agg({'group_idx':['count'],\n",
    "                                                    'mean_resume_score':['mean'],\n",
    "                                                    'std_resume_score':['mean'],\n",
    "                                                    'mean_selection_rate':['mean',percentile(50)]})\n",
    "\n",
    "rename_map = {('group_idx', 'count'): 'Number of applicants',\n",
    "              ('mean_resume_score', 'mean'): 'Mean resume score',\n",
    "              ('std_resume_score', 'mean'): 'Std dev resume score',\n",
    "              ('mean_selection_rate', 'mean'): 'Mean selection rate',\n",
    "              ('mean_selection_rate', 'p50'): 'Median selection rate'}\n",
    "\n",
    "job_gap_months_group_df.columns = [rename_map[tuple(col)] for col in job_gap_months_group_df.columns]\n",
    "job_gap_months_group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c7a58",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5975916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distribution of mean resume score for each group_idx in a histogram, remove grid and add n_bins\n",
    "n_bins = 20\n",
    "\n",
    "plt.hist(df[df['gender']=='M'].groupby(['group_idx'])['resume_score'].mean(), n_bins, alpha=0.5, label='Male')\n",
    "plt.hist(df[df['gender']=='F'].groupby(['group_idx'])['resume_score'].mean(), n_bins, alpha=0.5, label='Female')\n",
    "plt.hist(df[df['gender']=='N/A'].groupby(['group_idx'])['resume_score'].mean(), n_bins, alpha=0.5, label='N/A')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696855a0",
   "metadata": {},
   "source": [
    "### Ethnicity based discrepancies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_group_df = dedup_df.groupby(['ethnicity']).agg({'group_idx':['count'],\n",
    "                                                    'mean_resume_score':['mean'],\n",
    "                                                    'std_resume_score':['mean'],\n",
    "                                                    'mean_selection_rate':['mean',percentile(50)]})\n",
    "\n",
    "rename_map = {('group_idx', 'count'): 'Number of applicants',\n",
    "              ('mean_resume_score', 'mean'): 'Mean resume score',\n",
    "              ('std_resume_score', 'mean'): 'Std dev resume score',\n",
    "              ('mean_selection_rate', 'mean'): 'Mean selection rate',\n",
    "              ('mean_selection_rate', 'p50'): 'Median selection rate'}\n",
    "\n",
    "ethnicity_group_df.columns = [rename_map[tuple(col)] for col in ethnicity_group_df.columns]\n",
    "ethnicity_group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9db04b",
   "metadata": {},
   "source": [
    "### Work auth based discrepancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_auth_group_df = dedup_df.groupby(['work_auth']).agg({'group_idx':['count'],\n",
    "                                                    'mean_resume_score':['mean'],\n",
    "                                                    'std_resume_score':['mean'],\n",
    "                                                    'mean_selection_rate':['mean',percentile(50)]})\n",
    "\n",
    "rename_map = {('group_idx', 'count'): 'Number of applicants',\n",
    "              ('mean_resume_score', 'mean'): 'Mean resume score',\n",
    "              ('std_resume_score', 'mean'): 'Std dev resume score',\n",
    "              ('mean_selection_rate', 'mean'): 'Mean selection rate',\n",
    "              ('mean_selection_rate', 'p50'): 'Median selection rate'}\n",
    "\n",
    "work_auth_group_df.columns = [rename_map[tuple(col)] for col in work_auth_group_df.columns]\n",
    "work_auth_group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54193f68",
   "metadata": {},
   "source": [
    "### Disability based discrepancies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd54939",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_group_df = dedup_df.groupby(['disability']).agg({'group_idx':['count'],\n",
    "                                                    'mean_resume_score':['mean'],\n",
    "                                                    'std_resume_score':['mean'],\n",
    "                                                    'mean_selection_rate':['mean',percentile(50)]})\n",
    "\n",
    "rename_map = {('group_idx', 'count'): 'Number of applicants',\n",
    "              ('mean_resume_score', 'mean'): 'Mean resume score',\n",
    "              ('std_resume_score', 'mean'): 'Std dev resume score',\n",
    "              ('mean_selection_rate', 'mean'): 'Mean selection rate',\n",
    "              ('mean_selection_rate', 'p50'): 'Median selection rate'}\n",
    "\n",
    "disability_group_df.columns = [rename_map[tuple(col)] for col in disability_group_df.columns]\n",
    "disability_group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793752a9",
   "metadata": {},
   "source": [
    "### Veteran status based discrepancies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "veteran_status_group_df = dedup_df.groupby(['veteran_status']).agg({'group_idx':['count'],\n",
    "                                                    'mean_resume_score':['mean'],\n",
    "                                                    'std_resume_score':['mean'],\n",
    "                                                    'mean_selection_rate':['mean',percentile(50)]})\n",
    "\n",
    "rename_map = {('group_idx', 'count'): 'Number of applicants',\n",
    "              ('mean_resume_score', 'mean'): 'Mean resume score',\n",
    "              ('std_resume_score', 'mean'): 'Std dev resume score',\n",
    "              ('mean_selection_rate', 'mean'): 'Mean selection rate',\n",
    "              ('mean_selection_rate', 'p50'): 'Median selection rate'}\n",
    "\n",
    "veteran_status_group_df.columns = [rename_map[tuple(col)] for col in veteran_status_group_df.columns]\n",
    "veteran_status_group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8b018",
   "metadata": {},
   "source": [
    "### Degree level based discrepancies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_group_df = dedup_df.groupby(['degree']).agg({'group_idx':['count'],\n",
    "                                                    'mean_resume_score':['mean'],\n",
    "                                                    'std_resume_score':['mean'],\n",
    "                                                    'mean_selection_rate':['mean',percentile(50)]})\n",
    "\n",
    "rename_map = {('group_idx', 'count'): 'Number of applicants',\n",
    "              ('mean_resume_score', 'mean'): 'Mean resume score',\n",
    "              ('std_resume_score', 'mean'): 'Std dev resume score',\n",
    "              ('mean_selection_rate', 'mean'): 'Mean selection rate',\n",
    "              ('mean_selection_rate', 'p50'): 'Median selection rate'}\n",
    "\n",
    "degree_group_df.columns = [rename_map[tuple(col)] for col in degree_group_df.columns]\n",
    "degree_group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57dd8db",
   "metadata": {},
   "source": [
    "### GPA bins based discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpa_bins_group_df = dedup_df.groupby(['gpa_bins']).agg({'group_idx':['count'],\n",
    "                                                    'mean_resume_score':['mean'],\n",
    "                                                    'std_resume_score':['mean'],\n",
    "                                                    'mean_selection_rate':['mean',percentile(50)]})\n",
    "\n",
    "rename_map = {('group_idx', 'count'): 'Number of applicants',\n",
    "              ('mean_resume_score', 'mean'): 'Mean resume score',\n",
    "              ('std_resume_score', 'mean'): 'Std dev resume score',\n",
    "              ('mean_selection_rate', 'mean'): 'Mean selection rate',\n",
    "              ('mean_selection_rate', 'p50'): 'Median selection rate'}\n",
    "\n",
    "gpa_bins_group_df.columns = [rename_map[tuple(col)] for col in gpa_bins_group_df.columns]\n",
    "gpa_bins_group_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
